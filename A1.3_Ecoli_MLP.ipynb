{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ecoli Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pylab as plt\n",
    "import sklearn\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 42\n",
    "np.random.seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEQUENCE_NAME</th>\n",
       "      <th>MCG</th>\n",
       "      <th>GVH</th>\n",
       "      <th>LIP</th>\n",
       "      <th>CHG</th>\n",
       "      <th>AAC</th>\n",
       "      <th>ALM1</th>\n",
       "      <th>ALM2</th>\n",
       "      <th>SITE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAT_ECOLI</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.35</td>\n",
       "      <td>cp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACEA_ECOLI</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.44</td>\n",
       "      <td>cp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACEK_ECOLI</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.46</td>\n",
       "      <td>cp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACKA_ECOLI</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.36</td>\n",
       "      <td>cp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADI_ECOLI</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.35</td>\n",
       "      <td>cp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  SEQUENCE_NAME   MCG   GVH   LIP  CHG   AAC  ALM1  ALM2 SITE\n",
       "0     AAT_ECOLI  0.49  0.29  0.48  0.5  0.56  0.24  0.35   cp\n",
       "1    ACEA_ECOLI  0.07  0.40  0.48  0.5  0.54  0.35  0.44   cp\n",
       "2    ACEK_ECOLI  0.56  0.40  0.48  0.5  0.49  0.37  0.46   cp\n",
       "3    ACKA_ECOLI  0.59  0.49  0.48  0.5  0.52  0.45  0.36   cp\n",
       "4     ADI_ECOLI  0.23  0.32  0.48  0.5  0.55  0.25  0.35   cp"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('ecoli.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MCG</th>\n",
       "      <th>GVH</th>\n",
       "      <th>LIP</th>\n",
       "      <th>CHG</th>\n",
       "      <th>AAC</th>\n",
       "      <th>ALM1</th>\n",
       "      <th>ALM2</th>\n",
       "      <th>SITE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.49</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.35</td>\n",
       "      <td>cp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.44</td>\n",
       "      <td>cp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.56</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.46</td>\n",
       "      <td>cp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.59</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.36</td>\n",
       "      <td>cp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.35</td>\n",
       "      <td>cp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    MCG   GVH   LIP  CHG   AAC  ALM1  ALM2 SITE\n",
       "0  0.49  0.29  0.48  0.5  0.56  0.24  0.35   cp\n",
       "1  0.07  0.40  0.48  0.5  0.54  0.35  0.44   cp\n",
       "2  0.56  0.40  0.48  0.5  0.49  0.37  0.46   cp\n",
       "3  0.59  0.49  0.48  0.5  0.52  0.45  0.36   cp\n",
       "4  0.23  0.32  0.48  0.5  0.55  0.25  0.35   cp"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df['SEQUENCE_NAME']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cp     143\n",
       "im      77\n",
       "pp      52\n",
       "imU     35\n",
       "om      20\n",
       "omL      5\n",
       "imL      2\n",
       "imS      2\n",
       "Name: SITE, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['SITE'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most of the dataset's samples fall within the 'cp'(cytoplasm), 'im'(inner membrane without signal sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### To remove all the classes except for cp and im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_array = ['pp','imU','om','omL','imL','imS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting  all the rows except for cp and im\n",
    "df = df[~df['SITE'].isin(cl_array)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cp    143\n",
       "im     77\n",
       "Name: SITE, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['SITE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.SITE.replace(('cp', 'im'),(1,0), inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (220, 8)\n",
      "Data Types: \n",
      " MCG     float64\n",
      "GVH     float64\n",
      "LIP     float64\n",
      "CHG     float64\n",
      "AAC     float64\n",
      "ALM1    float64\n",
      "ALM2    float64\n",
      "SITE      int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape:\", df.shape)\n",
    "\n",
    "print(\"Data Types: \\n\", df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MCG</th>\n",
       "      <th>GVH</th>\n",
       "      <th>LIP</th>\n",
       "      <th>CHG</th>\n",
       "      <th>AAC</th>\n",
       "      <th>ALM1</th>\n",
       "      <th>ALM2</th>\n",
       "      <th>SITE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.49</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.44</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.56</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.46</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.59</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    MCG   GVH   LIP  CHG   AAC  ALM1  ALM2  SITE\n",
       "0  0.49  0.29  0.48  0.5  0.56  0.24  0.35     1\n",
       "1  0.07  0.40  0.48  0.5  0.54  0.35  0.44     1\n",
       "2  0.56  0.40  0.48  0.5  0.49  0.37  0.46     1\n",
       "3  0.59  0.49  0.48  0.5  0.52  0.45  0.36     1\n",
       "4  0.23  0.32  0.48  0.5  0.55  0.25  0.35     1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MCG</th>\n",
       "      <th>GVH</th>\n",
       "      <th>LIP</th>\n",
       "      <th>CHG</th>\n",
       "      <th>AAC</th>\n",
       "      <th>ALM1</th>\n",
       "      <th>ALM2</th>\n",
       "      <th>SITE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>220.000000</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>220.0</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>220.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.403773</td>\n",
       "      <td>0.440136</td>\n",
       "      <td>0.482364</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.483045</td>\n",
       "      <td>0.468364</td>\n",
       "      <td>0.512545</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.161516</td>\n",
       "      <td>0.098173</td>\n",
       "      <td>0.035058</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.105143</td>\n",
       "      <td>0.235186</td>\n",
       "      <td>0.203211</td>\n",
       "      <td>0.478057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.290000</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.367500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.502500</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.552500</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              MCG         GVH         LIP    CHG         AAC        ALM1  \\\n",
       "count  220.000000  220.000000  220.000000  220.0  220.000000  220.000000   \n",
       "mean     0.403773    0.440136    0.482364    0.5    0.483045    0.468364   \n",
       "std      0.161516    0.098173    0.035058    0.0    0.105143    0.235186   \n",
       "min      0.000000    0.160000    0.480000    0.5    0.000000    0.030000   \n",
       "25%      0.290000    0.370000    0.480000    0.5    0.420000    0.280000   \n",
       "50%      0.400000    0.440000    0.480000    0.5    0.480000    0.375000   \n",
       "75%      0.510000    0.502500    0.480000    0.5    0.552500    0.710000   \n",
       "max      0.890000    0.760000    1.000000    0.5    0.740000    1.000000   \n",
       "\n",
       "             ALM2        SITE  \n",
       "count  220.000000  220.000000  \n",
       "mean     0.512545    0.650000  \n",
       "std      0.203211    0.478057  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.367500    0.000000  \n",
       "50%      0.440000    1.000000  \n",
       "75%      0.710000    1.000000  \n",
       "max      0.990000    1.000000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features & Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop('SITE',axis=1)\n",
    "y=df['SITE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model. (20-10-5) if all the classes included.\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=7, activation='relu'))\n",
    "model.add(Dense(5, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Compile model\n",
    "model.compile(loss='BinaryCrossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "18/18 - 1s - loss: 0.6968 - accuracy: 0.3466\n",
      "Epoch 2/200\n",
      "18/18 - 0s - loss: 0.6880 - accuracy: 0.7557\n",
      "Epoch 3/200\n",
      "18/18 - 0s - loss: 0.6837 - accuracy: 0.8409\n",
      "Epoch 4/200\n",
      "18/18 - 0s - loss: 0.6797 - accuracy: 0.8920\n",
      "Epoch 5/200\n",
      "18/18 - 0s - loss: 0.6763 - accuracy: 0.9091\n",
      "Epoch 6/200\n",
      "18/18 - 0s - loss: 0.6728 - accuracy: 0.8920\n",
      "Epoch 7/200\n",
      "18/18 - 0s - loss: 0.6691 - accuracy: 0.9034\n",
      "Epoch 8/200\n",
      "18/18 - 0s - loss: 0.6655 - accuracy: 0.9091\n",
      "Epoch 9/200\n",
      "18/18 - 0s - loss: 0.6616 - accuracy: 0.9091\n",
      "Epoch 10/200\n",
      "18/18 - 0s - loss: 0.6575 - accuracy: 0.9205\n",
      "Epoch 11/200\n",
      "18/18 - 0s - loss: 0.6530 - accuracy: 0.9261\n",
      "Epoch 12/200\n",
      "18/18 - 0s - loss: 0.6490 - accuracy: 0.9375\n",
      "Epoch 13/200\n",
      "18/18 - 0s - loss: 0.6436 - accuracy: 0.9432\n",
      "Epoch 14/200\n",
      "18/18 - 0s - loss: 0.6390 - accuracy: 0.9489\n",
      "Epoch 15/200\n",
      "18/18 - 0s - loss: 0.6336 - accuracy: 0.9716\n",
      "Epoch 16/200\n",
      "18/18 - 0s - loss: 0.6279 - accuracy: 0.9716\n",
      "Epoch 17/200\n",
      "18/18 - 0s - loss: 0.6223 - accuracy: 0.9773\n",
      "Epoch 18/200\n",
      "18/18 - 0s - loss: 0.6164 - accuracy: 0.9773\n",
      "Epoch 19/200\n",
      "18/18 - 0s - loss: 0.6099 - accuracy: 0.9716\n",
      "Epoch 20/200\n",
      "18/18 - 0s - loss: 0.6031 - accuracy: 0.9716\n",
      "Epoch 21/200\n",
      "18/18 - 0s - loss: 0.5956 - accuracy: 0.9659\n",
      "Epoch 22/200\n",
      "18/18 - 0s - loss: 0.5891 - accuracy: 0.9545\n",
      "Epoch 23/200\n",
      "18/18 - 0s - loss: 0.5812 - accuracy: 0.9545\n",
      "Epoch 24/200\n",
      "18/18 - 0s - loss: 0.5736 - accuracy: 0.9489\n",
      "Epoch 25/200\n",
      "18/18 - 0s - loss: 0.5657 - accuracy: 0.9545\n",
      "Epoch 26/200\n",
      "18/18 - 0s - loss: 0.5578 - accuracy: 0.9489\n",
      "Epoch 27/200\n",
      "18/18 - 0s - loss: 0.5500 - accuracy: 0.9489\n",
      "Epoch 28/200\n",
      "18/18 - 0s - loss: 0.5425 - accuracy: 0.9489\n",
      "Epoch 29/200\n",
      "18/18 - 0s - loss: 0.5337 - accuracy: 0.9489\n",
      "Epoch 30/200\n",
      "18/18 - 0s - loss: 0.5256 - accuracy: 0.9489\n",
      "Epoch 31/200\n",
      "18/18 - 0s - loss: 0.5173 - accuracy: 0.9489\n",
      "Epoch 32/200\n",
      "18/18 - 0s - loss: 0.5094 - accuracy: 0.9489\n",
      "Epoch 33/200\n",
      "18/18 - 0s - loss: 0.5017 - accuracy: 0.9432\n",
      "Epoch 34/200\n",
      "18/18 - 0s - loss: 0.4945 - accuracy: 0.9489\n",
      "Epoch 35/200\n",
      "18/18 - 0s - loss: 0.4871 - accuracy: 0.9432\n",
      "Epoch 36/200\n",
      "18/18 - 0s - loss: 0.4786 - accuracy: 0.9432\n",
      "Epoch 37/200\n",
      "18/18 - 0s - loss: 0.4713 - accuracy: 0.9489\n",
      "Epoch 38/200\n",
      "18/18 - 0s - loss: 0.4642 - accuracy: 0.9489\n",
      "Epoch 39/200\n",
      "18/18 - 0s - loss: 0.4568 - accuracy: 0.9489\n",
      "Epoch 40/200\n",
      "18/18 - 0s - loss: 0.4501 - accuracy: 0.9489\n",
      "Epoch 41/200\n",
      "18/18 - 0s - loss: 0.4457 - accuracy: 0.9318\n",
      "Epoch 42/200\n",
      "18/18 - 0s - loss: 0.4366 - accuracy: 0.9545\n",
      "Epoch 43/200\n",
      "18/18 - 0s - loss: 0.4298 - accuracy: 0.9489\n",
      "Epoch 44/200\n",
      "18/18 - 0s - loss: 0.4240 - accuracy: 0.9489\n",
      "Epoch 45/200\n",
      "18/18 - 0s - loss: 0.4174 - accuracy: 0.9489\n",
      "Epoch 46/200\n",
      "18/18 - 0s - loss: 0.4125 - accuracy: 0.9489\n",
      "Epoch 47/200\n",
      "18/18 - 0s - loss: 0.4049 - accuracy: 0.9489\n",
      "Epoch 48/200\n",
      "18/18 - 0s - loss: 0.3998 - accuracy: 0.9489\n",
      "Epoch 49/200\n",
      "18/18 - 0s - loss: 0.3939 - accuracy: 0.9489\n",
      "Epoch 50/200\n",
      "18/18 - 0s - loss: 0.3885 - accuracy: 0.9489\n",
      "Epoch 51/200\n",
      "18/18 - 0s - loss: 0.3831 - accuracy: 0.9489\n",
      "Epoch 52/200\n",
      "18/18 - 0s - loss: 0.3780 - accuracy: 0.9489\n",
      "Epoch 53/200\n",
      "18/18 - 0s - loss: 0.3729 - accuracy: 0.9489\n",
      "Epoch 54/200\n",
      "18/18 - 0s - loss: 0.3679 - accuracy: 0.9489\n",
      "Epoch 55/200\n",
      "18/18 - 0s - loss: 0.3631 - accuracy: 0.9489\n",
      "Epoch 56/200\n",
      "18/18 - 0s - loss: 0.3583 - accuracy: 0.9489\n",
      "Epoch 57/200\n",
      "18/18 - 0s - loss: 0.3540 - accuracy: 0.9545\n",
      "Epoch 58/200\n",
      "18/18 - 0s - loss: 0.3496 - accuracy: 0.9489\n",
      "Epoch 59/200\n",
      "18/18 - 0s - loss: 0.3459 - accuracy: 0.9489\n",
      "Epoch 60/200\n",
      "18/18 - 0s - loss: 0.3408 - accuracy: 0.9489\n",
      "Epoch 61/200\n",
      "18/18 - 0s - loss: 0.3363 - accuracy: 0.9489\n",
      "Epoch 62/200\n",
      "18/18 - 0s - loss: 0.3327 - accuracy: 0.9602\n",
      "Epoch 63/200\n",
      "18/18 - 0s - loss: 0.3280 - accuracy: 0.9659\n",
      "Epoch 64/200\n",
      "18/18 - 0s - loss: 0.3242 - accuracy: 0.9545\n",
      "Epoch 65/200\n",
      "18/18 - 0s - loss: 0.3204 - accuracy: 0.9659\n",
      "Epoch 66/200\n",
      "18/18 - 0s - loss: 0.3163 - accuracy: 0.9659\n",
      "Epoch 67/200\n",
      "18/18 - 0s - loss: 0.3125 - accuracy: 0.9659\n",
      "Epoch 68/200\n",
      "18/18 - 0s - loss: 0.3107 - accuracy: 0.9602\n",
      "Epoch 69/200\n",
      "18/18 - 0s - loss: 0.3066 - accuracy: 0.9659\n",
      "Epoch 70/200\n",
      "18/18 - 0s - loss: 0.3019 - accuracy: 0.9602\n",
      "Epoch 71/200\n",
      "18/18 - 0s - loss: 0.2982 - accuracy: 0.9602\n",
      "Epoch 72/200\n",
      "18/18 - 0s - loss: 0.2946 - accuracy: 0.9602\n",
      "Epoch 73/200\n",
      "18/18 - 0s - loss: 0.2917 - accuracy: 0.9602\n",
      "Epoch 74/200\n",
      "18/18 - 0s - loss: 0.2880 - accuracy: 0.9602\n",
      "Epoch 75/200\n",
      "18/18 - 0s - loss: 0.2847 - accuracy: 0.9602\n",
      "Epoch 76/200\n",
      "18/18 - 0s - loss: 0.2816 - accuracy: 0.9602\n",
      "Epoch 77/200\n",
      "18/18 - 0s - loss: 0.2780 - accuracy: 0.9659\n",
      "Epoch 78/200\n",
      "18/18 - 0s - loss: 0.2750 - accuracy: 0.9659\n",
      "Epoch 79/200\n",
      "18/18 - 0s - loss: 0.2718 - accuracy: 0.9659\n",
      "Epoch 80/200\n",
      "18/18 - 0s - loss: 0.2691 - accuracy: 0.9659\n",
      "Epoch 81/200\n",
      "18/18 - 0s - loss: 0.2662 - accuracy: 0.9659\n",
      "Epoch 82/200\n",
      "18/18 - 0s - loss: 0.2641 - accuracy: 0.9659\n",
      "Epoch 83/200\n",
      "18/18 - 0s - loss: 0.2606 - accuracy: 0.9659\n",
      "Epoch 84/200\n",
      "18/18 - 0s - loss: 0.2592 - accuracy: 0.9659\n",
      "Epoch 85/200\n",
      "18/18 - 0s - loss: 0.2543 - accuracy: 0.9659\n",
      "Epoch 86/200\n",
      "18/18 - 0s - loss: 0.2519 - accuracy: 0.9659\n",
      "Epoch 87/200\n",
      "18/18 - 0s - loss: 0.2493 - accuracy: 0.9659\n",
      "Epoch 88/200\n",
      "18/18 - 0s - loss: 0.2466 - accuracy: 0.9659\n",
      "Epoch 89/200\n",
      "18/18 - 0s - loss: 0.2443 - accuracy: 0.9659\n",
      "Epoch 90/200\n",
      "18/18 - 0s - loss: 0.2420 - accuracy: 0.9659\n",
      "Epoch 91/200\n",
      "18/18 - 0s - loss: 0.2391 - accuracy: 0.9659\n",
      "Epoch 92/200\n",
      "18/18 - 0s - loss: 0.2366 - accuracy: 0.9659\n",
      "Epoch 93/200\n",
      "18/18 - 0s - loss: 0.2344 - accuracy: 0.9659\n",
      "Epoch 94/200\n",
      "18/18 - 0s - loss: 0.2319 - accuracy: 0.9659\n",
      "Epoch 95/200\n",
      "18/18 - 0s - loss: 0.2295 - accuracy: 0.9659\n",
      "Epoch 96/200\n",
      "18/18 - 0s - loss: 0.2273 - accuracy: 0.9659\n",
      "Epoch 97/200\n",
      "18/18 - 0s - loss: 0.2246 - accuracy: 0.9659\n",
      "Epoch 98/200\n",
      "18/18 - 0s - loss: 0.2224 - accuracy: 0.9659\n",
      "Epoch 99/200\n",
      "18/18 - 0s - loss: 0.2208 - accuracy: 0.9659\n",
      "Epoch 100/200\n",
      "18/18 - 0s - loss: 0.2191 - accuracy: 0.9716\n",
      "Epoch 101/200\n",
      "18/18 - 0s - loss: 0.2164 - accuracy: 0.9659\n",
      "Epoch 102/200\n",
      "18/18 - 0s - loss: 0.2140 - accuracy: 0.9659\n",
      "Epoch 103/200\n",
      "18/18 - 0s - loss: 0.2123 - accuracy: 0.9716\n",
      "Epoch 104/200\n",
      "18/18 - 0s - loss: 0.2098 - accuracy: 0.9716\n",
      "Epoch 105/200\n",
      "18/18 - 0s - loss: 0.2076 - accuracy: 0.9716\n",
      "Epoch 106/200\n",
      "18/18 - 0s - loss: 0.2059 - accuracy: 0.9659\n",
      "Epoch 107/200\n",
      "18/18 - 0s - loss: 0.2036 - accuracy: 0.9659\n",
      "Epoch 108/200\n",
      "18/18 - 0s - loss: 0.2023 - accuracy: 0.9716\n",
      "Epoch 109/200\n",
      "18/18 - 0s - loss: 0.1996 - accuracy: 0.9773\n",
      "Epoch 110/200\n",
      "18/18 - 0s - loss: 0.1989 - accuracy: 0.9773\n",
      "Epoch 111/200\n",
      "18/18 - 0s - loss: 0.1963 - accuracy: 0.9773\n",
      "Epoch 112/200\n",
      "18/18 - 0s - loss: 0.1941 - accuracy: 0.9773\n",
      "Epoch 113/200\n",
      "18/18 - 0s - loss: 0.1925 - accuracy: 0.9773\n",
      "Epoch 114/200\n",
      "18/18 - 0s - loss: 0.1907 - accuracy: 0.9773\n",
      "Epoch 115/200\n",
      "18/18 - 0s - loss: 0.1896 - accuracy: 0.9773\n",
      "Epoch 116/200\n",
      "18/18 - 0s - loss: 0.1870 - accuracy: 0.9773\n",
      "Epoch 117/200\n",
      "18/18 - 0s - loss: 0.1853 - accuracy: 0.9773\n",
      "Epoch 118/200\n",
      "18/18 - 0s - loss: 0.1837 - accuracy: 0.9773\n",
      "Epoch 119/200\n",
      "18/18 - 0s - loss: 0.1817 - accuracy: 0.9773\n",
      "Epoch 120/200\n",
      "18/18 - 0s - loss: 0.1812 - accuracy: 0.9773\n",
      "Epoch 121/200\n",
      "18/18 - 0s - loss: 0.1782 - accuracy: 0.9773\n",
      "Epoch 122/200\n",
      "18/18 - 0s - loss: 0.1779 - accuracy: 0.9773\n",
      "Epoch 123/200\n",
      "18/18 - 0s - loss: 0.1754 - accuracy: 0.9773\n",
      "Epoch 124/200\n",
      "18/18 - 0s - loss: 0.1741 - accuracy: 0.9773\n",
      "Epoch 125/200\n",
      "18/18 - 0s - loss: 0.1726 - accuracy: 0.9773\n",
      "Epoch 126/200\n",
      "18/18 - 0s - loss: 0.1707 - accuracy: 0.9773\n",
      "Epoch 127/200\n",
      "18/18 - 0s - loss: 0.1697 - accuracy: 0.9830\n",
      "Epoch 128/200\n",
      "18/18 - 0s - loss: 0.1681 - accuracy: 0.9773\n",
      "Epoch 129/200\n",
      "18/18 - 0s - loss: 0.1664 - accuracy: 0.9773\n",
      "Epoch 130/200\n",
      "18/18 - 0s - loss: 0.1650 - accuracy: 0.9773\n",
      "Epoch 131/200\n",
      "18/18 - 0s - loss: 0.1636 - accuracy: 0.9773\n",
      "Epoch 132/200\n",
      "18/18 - 0s - loss: 0.1621 - accuracy: 0.9773\n",
      "Epoch 133/200\n",
      "18/18 - 0s - loss: 0.1615 - accuracy: 0.9773\n",
      "Epoch 134/200\n",
      "18/18 - 0s - loss: 0.1591 - accuracy: 0.9773\n",
      "Epoch 135/200\n",
      "18/18 - 0s - loss: 0.1580 - accuracy: 0.9830\n",
      "Epoch 136/200\n",
      "18/18 - 0s - loss: 0.1566 - accuracy: 0.9830\n",
      "Epoch 137/200\n",
      "18/18 - 0s - loss: 0.1558 - accuracy: 0.9830\n",
      "Epoch 138/200\n",
      "18/18 - 0s - loss: 0.1542 - accuracy: 0.9830\n",
      "Epoch 139/200\n",
      "18/18 - 0s - loss: 0.1526 - accuracy: 0.9830\n",
      "Epoch 140/200\n",
      "18/18 - 0s - loss: 0.1520 - accuracy: 0.9773\n",
      "Epoch 141/200\n",
      "18/18 - 0s - loss: 0.1508 - accuracy: 0.9830\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 142/200\n",
      "18/18 - 0s - loss: 0.1491 - accuracy: 0.9830\n",
      "Epoch 143/200\n",
      "18/18 - 0s - loss: 0.1478 - accuracy: 0.9830\n",
      "Epoch 144/200\n",
      "18/18 - 0s - loss: 0.1463 - accuracy: 0.9830\n",
      "Epoch 145/200\n",
      "18/18 - 0s - loss: 0.1452 - accuracy: 0.9830\n",
      "Epoch 146/200\n",
      "18/18 - 0s - loss: 0.1453 - accuracy: 0.9830\n",
      "Epoch 147/200\n",
      "18/18 - 0s - loss: 0.1429 - accuracy: 0.9830\n",
      "Epoch 148/200\n",
      "18/18 - 0s - loss: 0.1418 - accuracy: 0.9830\n",
      "Epoch 149/200\n",
      "18/18 - 0s - loss: 0.1412 - accuracy: 0.9830\n",
      "Epoch 150/200\n",
      "18/18 - 0s - loss: 0.1402 - accuracy: 0.9830\n",
      "Epoch 151/200\n",
      "18/18 - 0s - loss: 0.1385 - accuracy: 0.9830\n",
      "Epoch 152/200\n",
      "18/18 - 0s - loss: 0.1382 - accuracy: 0.9830\n",
      "Epoch 153/200\n",
      "18/18 - 0s - loss: 0.1362 - accuracy: 0.9830\n",
      "Epoch 154/200\n",
      "18/18 - 0s - loss: 0.1352 - accuracy: 0.9830\n",
      "Epoch 155/200\n",
      "18/18 - 0s - loss: 0.1341 - accuracy: 0.9830\n",
      "Epoch 156/200\n",
      "18/18 - 0s - loss: 0.1328 - accuracy: 0.9830\n",
      "Epoch 157/200\n",
      "18/18 - 0s - loss: 0.1319 - accuracy: 0.9830\n",
      "Epoch 158/200\n",
      "18/18 - 0s - loss: 0.1313 - accuracy: 0.9830\n",
      "Epoch 159/200\n",
      "18/18 - 0s - loss: 0.1298 - accuracy: 0.9830\n",
      "Epoch 160/200\n",
      "18/18 - 0s - loss: 0.1288 - accuracy: 0.9830\n",
      "Epoch 161/200\n",
      "18/18 - 0s - loss: 0.1278 - accuracy: 0.9886\n",
      "Epoch 162/200\n",
      "18/18 - 0s - loss: 0.1267 - accuracy: 0.9830\n",
      "Epoch 163/200\n",
      "18/18 - 0s - loss: 0.1259 - accuracy: 0.9830\n",
      "Epoch 164/200\n",
      "18/18 - 0s - loss: 0.1252 - accuracy: 0.9886\n",
      "Epoch 165/200\n",
      "18/18 - 0s - loss: 0.1239 - accuracy: 0.9886\n",
      "Epoch 166/200\n",
      "18/18 - 0s - loss: 0.1231 - accuracy: 0.9830\n",
      "Epoch 167/200\n",
      "18/18 - 0s - loss: 0.1221 - accuracy: 0.9886\n",
      "Epoch 168/200\n",
      "18/18 - 0s - loss: 0.1211 - accuracy: 0.9886\n",
      "Epoch 169/200\n",
      "18/18 - 0s - loss: 0.1208 - accuracy: 0.9886\n",
      "Epoch 170/200\n",
      "18/18 - 0s - loss: 0.1191 - accuracy: 0.9886\n",
      "Epoch 171/200\n",
      "18/18 - 0s - loss: 0.1193 - accuracy: 0.9886\n",
      "Epoch 172/200\n",
      "18/18 - 0s - loss: 0.1174 - accuracy: 0.9886\n",
      "Epoch 173/200\n",
      "18/18 - 0s - loss: 0.1166 - accuracy: 0.9886\n",
      "Epoch 174/200\n",
      "18/18 - 0s - loss: 0.1161 - accuracy: 0.9886\n",
      "Epoch 175/200\n",
      "18/18 - 0s - loss: 0.1152 - accuracy: 0.9886\n",
      "Epoch 176/200\n",
      "18/18 - 0s - loss: 0.1141 - accuracy: 0.9943\n",
      "Epoch 177/200\n",
      "18/18 - 0s - loss: 0.1138 - accuracy: 0.9830\n",
      "Epoch 178/200\n",
      "18/18 - 0s - loss: 0.1124 - accuracy: 0.9886\n",
      "Epoch 179/200\n",
      "18/18 - 0s - loss: 0.1123 - accuracy: 0.9886\n",
      "Epoch 180/200\n",
      "18/18 - 0s - loss: 0.1106 - accuracy: 0.9943\n",
      "Epoch 181/200\n",
      "18/18 - 0s - loss: 0.1103 - accuracy: 0.9886\n",
      "Epoch 182/200\n",
      "18/18 - 0s - loss: 0.1091 - accuracy: 0.9943\n",
      "Epoch 183/200\n",
      "18/18 - 0s - loss: 0.1085 - accuracy: 0.9886\n",
      "Epoch 184/200\n",
      "18/18 - 0s - loss: 0.1078 - accuracy: 0.9943\n",
      "Epoch 185/200\n",
      "18/18 - 0s - loss: 0.1069 - accuracy: 0.9943\n",
      "Epoch 186/200\n",
      "18/18 - 0s - loss: 0.1064 - accuracy: 0.9943\n",
      "Epoch 187/200\n",
      "18/18 - 0s - loss: 0.1053 - accuracy: 0.9943\n",
      "Epoch 188/200\n",
      "18/18 - 0s - loss: 0.1046 - accuracy: 0.9943\n",
      "Epoch 189/200\n",
      "18/18 - 0s - loss: 0.1037 - accuracy: 0.9943\n",
      "Epoch 190/200\n",
      "18/18 - 0s - loss: 0.1032 - accuracy: 0.9943\n",
      "Epoch 191/200\n",
      "18/18 - 0s - loss: 0.1024 - accuracy: 0.9943\n",
      "Epoch 192/200\n",
      "18/18 - 0s - loss: 0.1019 - accuracy: 0.9943\n",
      "Epoch 193/200\n",
      "18/18 - 0s - loss: 0.1011 - accuracy: 0.9943\n",
      "Epoch 194/200\n",
      "18/18 - 0s - loss: 0.1004 - accuracy: 0.9943\n",
      "Epoch 195/200\n",
      "18/18 - 0s - loss: 0.0996 - accuracy: 0.9943\n",
      "Epoch 196/200\n",
      "18/18 - 0s - loss: 0.0989 - accuracy: 0.9943\n",
      "Epoch 197/200\n",
      "18/18 - 0s - loss: 0.0983 - accuracy: 0.9943\n",
      "Epoch 198/200\n",
      "18/18 - 0s - loss: 0.0977 - accuracy: 0.9943\n",
      "Epoch 199/200\n",
      "18/18 - 0s - loss: 0.0971 - accuracy: 0.9943\n",
      "Epoch 200/200\n",
      "18/18 - 0s - loss: 0.0964 - accuracy: 0.9943\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fac3f7b5640>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(X_train, y_train, epochs=200, batch_size=10, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.round(model.predict(X_test),0) \n",
    "# rounding off the y_prediction to get 1(cp) or 0(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15  1]\n",
      " [ 0 28]]\n"
     ]
    }
   ],
   "source": [
    "cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(cf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "ax = sns.heatmap(cf_matrix, annot=True, cmap='Blues')\n",
    "\n",
    "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values ');\n",
    "\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "ax.xaxis.set_ticklabels(['False','True'])\n",
    "ax.yaxis.set_ticklabels(['False','True'])\n",
    "\n",
    "## Display the visualization of the Confusion Matrix.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97        16\n",
      "           1       0.97      1.00      0.98        28\n",
      "\n",
      "    accuracy                           0.98        44\n",
      "   macro avg       0.98      0.97      0.98        44\n",
      "weighted avg       0.98      0.98      0.98        44\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 0.1252 - accuracy: 0.9773\n",
      "Model loss on the test set: 0.12523646652698517\n",
      "Model accuracy on the test set: 97.73%\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on the test set\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Model loss on the test set: {loss}\")\n",
    "print(f\"Model accuracy on the test set: {100*accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference paper for below model(7-15-8) @ https://www.ijltet.org/journal/15881228132.3062.pdf\n",
    "\n",
    "# create model\n",
    "model2 = Sequential()\n",
    "model2.add(Dense(7, input_dim=7, activation='relu'))\n",
    "model2.add(Dense(15, activation='relu'))\n",
    "model2.add(Dense(8, activation='relu'))\n",
    "model2.add(Dense(1, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss='BinaryCrossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "18/18 - 1s - loss: 0.6922 - accuracy: 0.5739\n",
      "Epoch 2/200\n",
      "18/18 - 0s - loss: 0.6769 - accuracy: 0.9375\n",
      "Epoch 3/200\n",
      "18/18 - 0s - loss: 0.6651 - accuracy: 0.9489\n",
      "Epoch 4/200\n",
      "18/18 - 0s - loss: 0.6513 - accuracy: 0.9659\n",
      "Epoch 5/200\n",
      "18/18 - 0s - loss: 0.6320 - accuracy: 0.9659\n",
      "Epoch 6/200\n",
      "18/18 - 0s - loss: 0.6057 - accuracy: 0.9659\n",
      "Epoch 7/200\n",
      "18/18 - 0s - loss: 0.5748 - accuracy: 0.9659\n",
      "Epoch 8/200\n",
      "18/18 - 0s - loss: 0.5459 - accuracy: 0.9318\n",
      "Epoch 9/200\n",
      "18/18 - 0s - loss: 0.5092 - accuracy: 0.9716\n",
      "Epoch 10/200\n",
      "18/18 - 0s - loss: 0.4746 - accuracy: 0.9659\n",
      "Epoch 11/200\n",
      "18/18 - 0s - loss: 0.4370 - accuracy: 0.9716\n",
      "Epoch 12/200\n",
      "18/18 - 0s - loss: 0.3994 - accuracy: 0.9716\n",
      "Epoch 13/200\n",
      "18/18 - 0s - loss: 0.3632 - accuracy: 0.9773\n",
      "Epoch 14/200\n",
      "18/18 - 0s - loss: 0.3276 - accuracy: 0.9830\n",
      "Epoch 15/200\n",
      "18/18 - 0s - loss: 0.2949 - accuracy: 0.9773\n",
      "Epoch 16/200\n",
      "18/18 - 0s - loss: 0.2660 - accuracy: 0.9773\n",
      "Epoch 17/200\n",
      "18/18 - 0s - loss: 0.2408 - accuracy: 0.9773\n",
      "Epoch 18/200\n",
      "18/18 - 0s - loss: 0.2176 - accuracy: 0.9830\n",
      "Epoch 19/200\n",
      "18/18 - 0s - loss: 0.1992 - accuracy: 0.9773\n",
      "Epoch 20/200\n",
      "18/18 - 0s - loss: 0.1812 - accuracy: 0.9830\n",
      "Epoch 21/200\n",
      "18/18 - 0s - loss: 0.1668 - accuracy: 0.9830\n",
      "Epoch 22/200\n",
      "18/18 - 0s - loss: 0.1553 - accuracy: 0.9830\n",
      "Epoch 23/200\n",
      "18/18 - 0s - loss: 0.1442 - accuracy: 0.9886\n",
      "Epoch 24/200\n",
      "18/18 - 0s - loss: 0.1373 - accuracy: 0.9830\n",
      "Epoch 25/200\n",
      "18/18 - 0s - loss: 0.1324 - accuracy: 0.9830\n",
      "Epoch 26/200\n",
      "18/18 - 0s - loss: 0.1218 - accuracy: 0.9830\n",
      "Epoch 27/200\n",
      "18/18 - 0s - loss: 0.1133 - accuracy: 0.9886\n",
      "Epoch 28/200\n",
      "18/18 - 0s - loss: 0.1097 - accuracy: 0.9830\n",
      "Epoch 29/200\n",
      "18/18 - 0s - loss: 0.1048 - accuracy: 0.9830\n",
      "Epoch 30/200\n",
      "18/18 - 0s - loss: 0.1004 - accuracy: 0.9886\n",
      "Epoch 31/200\n",
      "18/18 - 0s - loss: 0.0963 - accuracy: 0.9830\n",
      "Epoch 32/200\n",
      "18/18 - 0s - loss: 0.0931 - accuracy: 0.9886\n",
      "Epoch 33/200\n",
      "18/18 - 0s - loss: 0.0892 - accuracy: 0.9886\n",
      "Epoch 34/200\n",
      "18/18 - 0s - loss: 0.0892 - accuracy: 0.9830\n",
      "Epoch 35/200\n",
      "18/18 - 0s - loss: 0.0856 - accuracy: 0.9886\n",
      "Epoch 36/200\n",
      "18/18 - 0s - loss: 0.0820 - accuracy: 0.9830\n",
      "Epoch 37/200\n",
      "18/18 - 0s - loss: 0.0830 - accuracy: 0.9886\n",
      "Epoch 38/200\n",
      "18/18 - 0s - loss: 0.0766 - accuracy: 0.9830\n",
      "Epoch 39/200\n",
      "18/18 - 0s - loss: 0.0777 - accuracy: 0.9830\n",
      "Epoch 40/200\n",
      "18/18 - 0s - loss: 0.0744 - accuracy: 0.9886\n",
      "Epoch 41/200\n",
      "18/18 - 0s - loss: 0.0730 - accuracy: 0.9886\n",
      "Epoch 42/200\n",
      "18/18 - 0s - loss: 0.0722 - accuracy: 0.9886\n",
      "Epoch 43/200\n",
      "18/18 - 0s - loss: 0.0709 - accuracy: 0.9886\n",
      "Epoch 44/200\n",
      "18/18 - 0s - loss: 0.0684 - accuracy: 0.9886\n",
      "Epoch 45/200\n",
      "18/18 - 0s - loss: 0.0706 - accuracy: 0.9886\n",
      "Epoch 46/200\n",
      "18/18 - 0s - loss: 0.0701 - accuracy: 0.9830\n",
      "Epoch 47/200\n",
      "18/18 - 0s - loss: 0.0655 - accuracy: 0.9886\n",
      "Epoch 48/200\n",
      "18/18 - 0s - loss: 0.0665 - accuracy: 0.9886\n",
      "Epoch 49/200\n",
      "18/18 - 0s - loss: 0.0658 - accuracy: 0.9886\n",
      "Epoch 50/200\n",
      "18/18 - 0s - loss: 0.0659 - accuracy: 0.9830\n",
      "Epoch 51/200\n",
      "18/18 - 0s - loss: 0.0656 - accuracy: 0.9830\n",
      "Epoch 52/200\n",
      "18/18 - 0s - loss: 0.0633 - accuracy: 0.9886\n",
      "Epoch 53/200\n",
      "18/18 - 0s - loss: 0.0619 - accuracy: 0.9886\n",
      "Epoch 54/200\n",
      "18/18 - 0s - loss: 0.0615 - accuracy: 0.9886\n",
      "Epoch 55/200\n",
      "18/18 - 0s - loss: 0.0614 - accuracy: 0.9886\n",
      "Epoch 56/200\n",
      "18/18 - 0s - loss: 0.0604 - accuracy: 0.9886\n",
      "Epoch 57/200\n",
      "18/18 - 0s - loss: 0.0600 - accuracy: 0.9886\n",
      "Epoch 58/200\n",
      "18/18 - 0s - loss: 0.0588 - accuracy: 0.9886\n",
      "Epoch 59/200\n",
      "18/18 - 0s - loss: 0.0603 - accuracy: 0.9886\n",
      "Epoch 60/200\n",
      "18/18 - 0s - loss: 0.0581 - accuracy: 0.9886\n",
      "Epoch 61/200\n",
      "18/18 - 0s - loss: 0.0598 - accuracy: 0.9886\n",
      "Epoch 62/200\n",
      "18/18 - 0s - loss: 0.0563 - accuracy: 0.9886\n",
      "Epoch 63/200\n",
      "18/18 - 0s - loss: 0.0570 - accuracy: 0.9886\n",
      "Epoch 64/200\n",
      "18/18 - 0s - loss: 0.0592 - accuracy: 0.9886\n",
      "Epoch 65/200\n",
      "18/18 - 0s - loss: 0.0559 - accuracy: 0.9886\n",
      "Epoch 66/200\n",
      "18/18 - 0s - loss: 0.0554 - accuracy: 0.9886\n",
      "Epoch 67/200\n",
      "18/18 - 0s - loss: 0.0563 - accuracy: 0.9886\n",
      "Epoch 68/200\n",
      "18/18 - 0s - loss: 0.0553 - accuracy: 0.9886\n",
      "Epoch 69/200\n",
      "18/18 - 0s - loss: 0.0576 - accuracy: 0.9886\n",
      "Epoch 70/200\n",
      "18/18 - 0s - loss: 0.0549 - accuracy: 0.9886\n",
      "Epoch 71/200\n",
      "18/18 - 0s - loss: 0.0548 - accuracy: 0.9886\n",
      "Epoch 72/200\n",
      "18/18 - 0s - loss: 0.0549 - accuracy: 0.9886\n",
      "Epoch 73/200\n",
      "18/18 - 0s - loss: 0.0543 - accuracy: 0.9886\n",
      "Epoch 74/200\n",
      "18/18 - 0s - loss: 0.0541 - accuracy: 0.9886\n",
      "Epoch 75/200\n",
      "18/18 - 0s - loss: 0.0549 - accuracy: 0.9886\n",
      "Epoch 76/200\n",
      "18/18 - 0s - loss: 0.0544 - accuracy: 0.9886\n",
      "Epoch 77/200\n",
      "18/18 - 0s - loss: 0.0549 - accuracy: 0.9886\n",
      "Epoch 78/200\n",
      "18/18 - 0s - loss: 0.0542 - accuracy: 0.9886\n",
      "Epoch 79/200\n",
      "18/18 - 0s - loss: 0.0552 - accuracy: 0.9886\n",
      "Epoch 80/200\n",
      "18/18 - 0s - loss: 0.0573 - accuracy: 0.9886\n",
      "Epoch 81/200\n",
      "18/18 - 0s - loss: 0.0554 - accuracy: 0.9830\n",
      "Epoch 82/200\n",
      "18/18 - 0s - loss: 0.0516 - accuracy: 0.9886\n",
      "Epoch 83/200\n",
      "18/18 - 0s - loss: 0.0520 - accuracy: 0.9886\n",
      "Epoch 84/200\n",
      "18/18 - 0s - loss: 0.0517 - accuracy: 0.9886\n",
      "Epoch 85/200\n",
      "18/18 - 0s - loss: 0.0532 - accuracy: 0.9886\n",
      "Epoch 86/200\n",
      "18/18 - 0s - loss: 0.0520 - accuracy: 0.9886\n",
      "Epoch 87/200\n",
      "18/18 - 0s - loss: 0.0514 - accuracy: 0.9886\n",
      "Epoch 88/200\n",
      "18/18 - 0s - loss: 0.0510 - accuracy: 0.9886\n",
      "Epoch 89/200\n",
      "18/18 - 0s - loss: 0.0515 - accuracy: 0.9886\n",
      "Epoch 90/200\n",
      "18/18 - 0s - loss: 0.0519 - accuracy: 0.9886\n",
      "Epoch 91/200\n",
      "18/18 - 0s - loss: 0.0516 - accuracy: 0.9886\n",
      "Epoch 92/200\n",
      "18/18 - 0s - loss: 0.0512 - accuracy: 0.9886\n",
      "Epoch 93/200\n",
      "18/18 - 0s - loss: 0.0548 - accuracy: 0.9886\n",
      "Epoch 94/200\n",
      "18/18 - 0s - loss: 0.0511 - accuracy: 0.9886\n",
      "Epoch 95/200\n",
      "18/18 - 0s - loss: 0.0512 - accuracy: 0.9886\n",
      "Epoch 96/200\n",
      "18/18 - 0s - loss: 0.0549 - accuracy: 0.9886\n",
      "Epoch 97/200\n",
      "18/18 - 0s - loss: 0.0492 - accuracy: 0.9886\n",
      "Epoch 98/200\n",
      "18/18 - 0s - loss: 0.0516 - accuracy: 0.9886\n",
      "Epoch 99/200\n",
      "18/18 - 0s - loss: 0.0503 - accuracy: 0.9886\n",
      "Epoch 100/200\n",
      "18/18 - 0s - loss: 0.0502 - accuracy: 0.9886\n",
      "Epoch 101/200\n",
      "18/18 - 0s - loss: 0.0521 - accuracy: 0.9886\n",
      "Epoch 102/200\n",
      "18/18 - 0s - loss: 0.0500 - accuracy: 0.9886\n",
      "Epoch 103/200\n",
      "18/18 - 0s - loss: 0.0522 - accuracy: 0.9886\n",
      "Epoch 104/200\n",
      "18/18 - 0s - loss: 0.0503 - accuracy: 0.9886\n",
      "Epoch 105/200\n",
      "18/18 - 0s - loss: 0.0518 - accuracy: 0.9886\n",
      "Epoch 106/200\n",
      "18/18 - 0s - loss: 0.0495 - accuracy: 0.9886\n",
      "Epoch 107/200\n",
      "18/18 - 0s - loss: 0.0515 - accuracy: 0.9886\n",
      "Epoch 108/200\n",
      "18/18 - 0s - loss: 0.0511 - accuracy: 0.9886\n",
      "Epoch 109/200\n",
      "18/18 - 0s - loss: 0.0497 - accuracy: 0.9886\n",
      "Epoch 110/200\n",
      "18/18 - 0s - loss: 0.0496 - accuracy: 0.9886\n",
      "Epoch 111/200\n",
      "18/18 - 0s - loss: 0.0487 - accuracy: 0.9886\n",
      "Epoch 112/200\n",
      "18/18 - 0s - loss: 0.0494 - accuracy: 0.9886\n",
      "Epoch 113/200\n",
      "18/18 - 0s - loss: 0.0501 - accuracy: 0.9886\n",
      "Epoch 114/200\n",
      "18/18 - 0s - loss: 0.0496 - accuracy: 0.9886\n",
      "Epoch 115/200\n",
      "18/18 - 0s - loss: 0.0511 - accuracy: 0.9886\n",
      "Epoch 116/200\n",
      "18/18 - 0s - loss: 0.0489 - accuracy: 0.9886\n",
      "Epoch 117/200\n",
      "18/18 - 0s - loss: 0.0563 - accuracy: 0.9886\n",
      "Epoch 118/200\n",
      "18/18 - 0s - loss: 0.0517 - accuracy: 0.9886\n",
      "Epoch 119/200\n",
      "18/18 - 0s - loss: 0.0492 - accuracy: 0.9886\n",
      "Epoch 120/200\n",
      "18/18 - 0s - loss: 0.0494 - accuracy: 0.9886\n",
      "Epoch 121/200\n",
      "18/18 - 0s - loss: 0.0512 - accuracy: 0.9886\n",
      "Epoch 122/200\n",
      "18/18 - 0s - loss: 0.0502 - accuracy: 0.9886\n",
      "Epoch 123/200\n",
      "18/18 - 0s - loss: 0.0509 - accuracy: 0.9886\n",
      "Epoch 124/200\n",
      "18/18 - 0s - loss: 0.0523 - accuracy: 0.9886\n",
      "Epoch 125/200\n",
      "18/18 - 0s - loss: 0.0487 - accuracy: 0.9886\n",
      "Epoch 126/200\n",
      "18/18 - 0s - loss: 0.0497 - accuracy: 0.9886\n",
      "Epoch 127/200\n",
      "18/18 - 0s - loss: 0.0488 - accuracy: 0.9886\n",
      "Epoch 128/200\n",
      "18/18 - 0s - loss: 0.0501 - accuracy: 0.9886\n",
      "Epoch 129/200\n",
      "18/18 - 0s - loss: 0.0487 - accuracy: 0.9886\n",
      "Epoch 130/200\n",
      "18/18 - 0s - loss: 0.0490 - accuracy: 0.9886\n",
      "Epoch 131/200\n",
      "18/18 - 0s - loss: 0.0489 - accuracy: 0.9886\n",
      "Epoch 132/200\n",
      "18/18 - 0s - loss: 0.0527 - accuracy: 0.9886\n",
      "Epoch 133/200\n",
      "18/18 - 0s - loss: 0.0483 - accuracy: 0.9886\n",
      "Epoch 134/200\n",
      "18/18 - 0s - loss: 0.0499 - accuracy: 0.9886\n",
      "Epoch 135/200\n",
      "18/18 - 0s - loss: 0.0489 - accuracy: 0.9886\n",
      "Epoch 136/200\n",
      "18/18 - 0s - loss: 0.0481 - accuracy: 0.9886\n",
      "Epoch 137/200\n",
      "18/18 - 0s - loss: 0.0501 - accuracy: 0.9886\n",
      "Epoch 138/200\n",
      "18/18 - 0s - loss: 0.0508 - accuracy: 0.9886\n",
      "Epoch 139/200\n",
      "18/18 - 0s - loss: 0.0552 - accuracy: 0.9886\n",
      "Epoch 140/200\n",
      "18/18 - 0s - loss: 0.0501 - accuracy: 0.9886\n",
      "Epoch 141/200\n",
      "18/18 - 0s - loss: 0.0488 - accuracy: 0.9886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 142/200\n",
      "18/18 - 0s - loss: 0.0477 - accuracy: 0.9886\n",
      "Epoch 143/200\n",
      "18/18 - 0s - loss: 0.0499 - accuracy: 0.9886\n",
      "Epoch 144/200\n",
      "18/18 - 0s - loss: 0.0478 - accuracy: 0.9886\n",
      "Epoch 145/200\n",
      "18/18 - 0s - loss: 0.0483 - accuracy: 0.9886\n",
      "Epoch 146/200\n",
      "18/18 - 0s - loss: 0.0495 - accuracy: 0.9886\n",
      "Epoch 147/200\n",
      "18/18 - 0s - loss: 0.0486 - accuracy: 0.9886\n",
      "Epoch 148/200\n",
      "18/18 - 0s - loss: 0.0507 - accuracy: 0.9886\n",
      "Epoch 149/200\n",
      "18/18 - 0s - loss: 0.0493 - accuracy: 0.9886\n",
      "Epoch 150/200\n",
      "18/18 - 0s - loss: 0.0509 - accuracy: 0.9886\n",
      "Epoch 151/200\n",
      "18/18 - 0s - loss: 0.0480 - accuracy: 0.9886\n",
      "Epoch 152/200\n",
      "18/18 - 0s - loss: 0.0501 - accuracy: 0.9886\n",
      "Epoch 153/200\n",
      "18/18 - 0s - loss: 0.0522 - accuracy: 0.9886\n",
      "Epoch 154/200\n",
      "18/18 - 0s - loss: 0.0533 - accuracy: 0.9886\n",
      "Epoch 155/200\n",
      "18/18 - 0s - loss: 0.0503 - accuracy: 0.9886\n",
      "Epoch 156/200\n",
      "18/18 - 0s - loss: 0.0496 - accuracy: 0.9886\n",
      "Epoch 157/200\n",
      "18/18 - 0s - loss: 0.0545 - accuracy: 0.9886\n",
      "Epoch 158/200\n",
      "18/18 - 0s - loss: 0.0499 - accuracy: 0.9886\n",
      "Epoch 159/200\n",
      "18/18 - 0s - loss: 0.0484 - accuracy: 0.9886\n",
      "Epoch 160/200\n",
      "18/18 - 0s - loss: 0.0478 - accuracy: 0.9886\n",
      "Epoch 161/200\n",
      "18/18 - 0s - loss: 0.0483 - accuracy: 0.9886\n",
      "Epoch 162/200\n",
      "18/18 - 0s - loss: 0.0484 - accuracy: 0.9886\n",
      "Epoch 163/200\n",
      "18/18 - 0s - loss: 0.0471 - accuracy: 0.9886\n",
      "Epoch 164/200\n",
      "18/18 - 0s - loss: 0.0493 - accuracy: 0.9886\n",
      "Epoch 165/200\n",
      "18/18 - 0s - loss: 0.0483 - accuracy: 0.9886\n",
      "Epoch 166/200\n",
      "18/18 - 0s - loss: 0.0518 - accuracy: 0.9886\n",
      "Epoch 167/200\n",
      "18/18 - 0s - loss: 0.0519 - accuracy: 0.9886\n",
      "Epoch 168/200\n",
      "18/18 - 0s - loss: 0.0474 - accuracy: 0.9886\n",
      "Epoch 169/200\n",
      "18/18 - 0s - loss: 0.0472 - accuracy: 0.9886\n",
      "Epoch 170/200\n",
      "18/18 - 0s - loss: 0.0471 - accuracy: 0.9886\n",
      "Epoch 171/200\n",
      "18/18 - 0s - loss: 0.0489 - accuracy: 0.9886\n",
      "Epoch 172/200\n",
      "18/18 - 0s - loss: 0.0477 - accuracy: 0.9886\n",
      "Epoch 173/200\n",
      "18/18 - 0s - loss: 0.0479 - accuracy: 0.9886\n",
      "Epoch 174/200\n",
      "18/18 - 0s - loss: 0.0476 - accuracy: 0.9886\n",
      "Epoch 175/200\n",
      "18/18 - 0s - loss: 0.0481 - accuracy: 0.9886\n",
      "Epoch 176/200\n",
      "18/18 - 0s - loss: 0.0518 - accuracy: 0.9886\n",
      "Epoch 177/200\n",
      "18/18 - 0s - loss: 0.0464 - accuracy: 0.9886\n",
      "Epoch 178/200\n",
      "18/18 - 0s - loss: 0.0475 - accuracy: 0.9886\n",
      "Epoch 179/200\n",
      "18/18 - 0s - loss: 0.0471 - accuracy: 0.9886\n",
      "Epoch 180/200\n",
      "18/18 - 0s - loss: 0.0491 - accuracy: 0.9886\n",
      "Epoch 181/200\n",
      "18/18 - 0s - loss: 0.0477 - accuracy: 0.9886\n",
      "Epoch 182/200\n",
      "18/18 - 0s - loss: 0.0471 - accuracy: 0.9886\n",
      "Epoch 183/200\n",
      "18/18 - 0s - loss: 0.0479 - accuracy: 0.9886\n",
      "Epoch 184/200\n",
      "18/18 - 0s - loss: 0.0516 - accuracy: 0.9886\n",
      "Epoch 185/200\n",
      "18/18 - 0s - loss: 0.0506 - accuracy: 0.9886\n",
      "Epoch 186/200\n",
      "18/18 - 0s - loss: 0.0452 - accuracy: 0.9886\n",
      "Epoch 187/200\n",
      "18/18 - 0s - loss: 0.0495 - accuracy: 0.9886\n",
      "Epoch 188/200\n",
      "18/18 - 0s - loss: 0.0488 - accuracy: 0.9886\n",
      "Epoch 189/200\n",
      "18/18 - 0s - loss: 0.0476 - accuracy: 0.9886\n",
      "Epoch 190/200\n",
      "18/18 - 0s - loss: 0.0478 - accuracy: 0.9886\n",
      "Epoch 191/200\n",
      "18/18 - 0s - loss: 0.0488 - accuracy: 0.9886\n",
      "Epoch 192/200\n",
      "18/18 - 0s - loss: 0.0480 - accuracy: 0.9886\n",
      "Epoch 193/200\n",
      "18/18 - 0s - loss: 0.0460 - accuracy: 0.9886\n",
      "Epoch 194/200\n",
      "18/18 - 0s - loss: 0.0476 - accuracy: 0.9886\n",
      "Epoch 195/200\n",
      "18/18 - 0s - loss: 0.0490 - accuracy: 0.9886\n",
      "Epoch 196/200\n",
      "18/18 - 0s - loss: 0.0485 - accuracy: 0.9886\n",
      "Epoch 197/200\n",
      "18/18 - 0s - loss: 0.0491 - accuracy: 0.9886\n",
      "Epoch 198/200\n",
      "18/18 - 0s - loss: 0.0469 - accuracy: 0.9886\n",
      "Epoch 199/200\n",
      "18/18 - 0s - loss: 0.0469 - accuracy: 0.9886\n",
      "Epoch 200/200\n",
      "18/18 - 0s - loss: 0.0472 - accuracy: 0.9886\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fac220eac10>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(X_train, y_train, epochs=200, batch_size=10, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0627 - accuracy: 0.9773\n",
      "Model loss on the test set: 0.0627438947558403\n",
      "Model accuracy on the test set: 97.73%\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on the test set\n",
    "loss, accuracy = model2.evaluate(X_test, y_test)\n",
    "print(f\"Model loss on the test set: {loss}\")\n",
    "print(f\"Model accuracy on the test set: {100*accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.round(model2.predict(X_test),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15  1]\n",
      " [ 0 28]]\n"
     ]
    }
   ],
   "source": [
    "cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(cf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "ax = sns.heatmap(cf_matrix, annot=True, cmap='Blues')\n",
    "\n",
    "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values ');\n",
    "\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "ax.xaxis.set_ticklabels(['False','True'])\n",
    "ax.yaxis.set_ticklabels(['False','True'])\n",
    "\n",
    "## Display the visualization of the Confusion Matrix.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97        16\n",
      "           1       0.97      1.00      0.98        28\n",
      "\n",
      "    accuracy                           0.98        44\n",
      "   macro avg       0.98      0.97      0.98        44\n",
      "weighted avg       0.98      0.98      0.98        44\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
